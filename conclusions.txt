0.2116: MLPClassifier(hidden_layer_sizes=(1, ), activation='tanh', learning_rate_init=0.01, momentum=0.0) and StandardScaler()
0.5210: MLPClassifier(hidden_layer_sizes=(10, 10), activation='tanh', learning_rate_init=0.01, momentum=0.0, max_iter=2000) and StandardScaler()
0.5296: MLPClassifier(hidden_layer_sizes=(10, ), activation='tanh', learning_rate_init=0.01, momentum=0.0) and StandardScaler()
0.5362: MLPClassifier(hidden_layer_sizes=(10, ), activation='tanh', learning_rate_init=0.01, momentum=0.0, max_iter=20) and StandardScaler()
0.5378: MLPClassifier(hidden_layer_sizes=(10, ), activation='tanh', learning_rate_init=0.00001, momentum=0.0) and StandardScaler()
0.5880: LinearDiscriminantAnalysis
0.6142: MLPClassifier(hidden_layer_sizes=(10, 10), learning_rate_init=0.01, momentum=0.0, max_iter=2000) and StandardScaler()
0.6400: SVC, C=0.1
0.6490: MLPClassifier(hidden_layer_sizes=(100, 100), learning_rate_init=0.01, momentum=0.0, max_iter=2000) and StandardScaler()
0.6720: MLPClassifier(hidden_layer_sizes=(32, 32), momentum=0.0) and StandardScaler()
0.6968: MLPClassifier(hidden_layer_sizes=(32, 32), momentum=0.0, alpha=0.1) and StandardScaler()
0.7006: SVC, C=1.0 and Normalizer(norm='l1')
0.7180: MLPClassifier(solver='sgd', hidden_layer_sizes=(100, 100), learning_rate_init=0.01, max_iter=20, alpha=0.005) and StandardScaler()
0.7350: SVC, C=1.0
0.7356: MLPClassifier(solver='sgd', hidden_layer_sizes=(100, 100), learning_rate_init=0.01, max_iter=80, alpha=0.005) and StandardScaler()
0.7370: SVC, C=1.0 and StandardScaler()
0.7412: MLPClassifier(solver='sgd', hidden_layer_sizes=(100, 100, 100), learning_rate_init=0.01, max_iter=80, alpha=0.005) and StandardScaler()
0.7554: SVC, C=10.0
0.7612: SVC, C=10.0 and StandardScaler()
0.7616: SVC, C=1000.0 and StandardScaler()
0.7628: SVC, C=100.0 and StandardScaler()
0.7630: SVC, C=75.0 and StandardScaler()

CNN:
    0.8358:
        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 1)))
        model.add(MaxPool2D(pool_size=(2, 2)))
        model.add(Conv2D(32, (3, 3), activation='relu'))
        model.add(MaxPool2D((2, 2)))
        model.add(Flatten())
        model.add(Dense(64, activation='relu'))
        model.add(Dense(9))

        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
        optimizer = tf.keras.optimizers.Adam(lr=0.001)
        model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])

        model.fit(train_images, train_labels, batch_size=32, epochs=13, verbose=2)

    0.8450 (try 2):
        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 1)))
        model.add(MaxPool2D(pool_size=(2, 2)))
        model.add(Conv2D(32, (3, 3), activation='relu'))
        model.add(MaxPool2D((2, 2)))
        model.add(Flatten())
        model.add(Dense(64, activation='relu'))
        model.add(Dense(9))

        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
        optimizer = tf.keras.optimizers.Adam(lr=0.0005)
        model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])

        model.fit(train_images, train_labels, batch_size=32, epochs=20, verbose=2)

    0.8626 (try 5):
        la fel ca try 4, doar ca am folosit Dropout(0.3)


    0.8652 (try 4):
        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 1)))
        model.add(Conv2D(32, (3, 3), activation='relu'))
        model.add(MaxPool2D(pool_size=(2, 2)))
        model.add(Conv2D(64, (3, 3), activation='relu'))
        model.add(MaxPool2D((2, 2)))
        model.add(Dropout(0.1))
        model.add(Flatten())
        model.add(Dense(64, activation='relu'))
        model.add(Dropout(0.1))
        model.add(Dense(64, activation='relu'))
        model.add(Dense(9))

        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
        optimizer = tf.keras.optimizers.Adam(lr=0.0005)
        model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])

        model.fit(
            train_images,
            train_labels,
            batch_size=32,
            epochs=20,
            verbose=2,
            validation_data=(validation_images, validation_labels)
        )

    8668 (try 7):
        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 1)))
        model.add(Conv2D(32, (3, 3), activation='relu'))
        model.add(MaxPool2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))
        model.add(Conv2D(64, (3, 3), activation='relu'))
        model.add(Conv2D(64, (3, 3), activation='relu'))
        model.add(MaxPool2D((2, 2)))
        model.add(Dropout(0.25))
        model.add(Flatten())
        model.add(Dense(128, activation='relu'))
        model.add(Dense(32, activation='relu'))
        model.add(Dropout(0.25))
        model.add(Dense(9))

        loss = tf.keras.losses.MeanSquaredError()
        optimizer = tf.keras.optimizers.Adam(lr=0.001)
        model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])

        model.fit(
            train_images,
            train_labels,
            batch_size=32,
            epochs=30,
            verbose=2,
            validation_data=(validation_images, validation_labels)
        )

    0.8842 (try 8):
        model = Sequential()
        model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 1)))
        model.add(Conv2D(64, (3, 3), activation='relu'))
        model.add(MaxPool2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))
        model.add(Conv2D(128, (3, 3), activation='relu'))
        model.add(Conv2D(256, (3, 3), activation='relu'))
        model.add(MaxPool2D((2, 2)))
        model.add(Dropout(0.25))
        model.add(Flatten())
        model.add(Dense(512, activation='relu'))
        model.add(Dropout(0.3))
        model.add(Dense(9, activation='softmax'))

        loss = tf.keras.losses.MeanSquaredError()
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
        model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])

        model.fit(
            train_images,
            train_labels,
            batch_size=256,
            epochs=50,
            verbose=2,
            validation_data=(validation_images, validation_labels)
        )

    0.8976 (try 9):
        model = Sequential()
        model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 1)))
        model.add(Conv2D(64, (3, 3), activation='relu'))
        model.add(MaxPool2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))
        model.add(Conv2D(128, (3, 3), activation='relu'))
        model.add(Conv2D(256, (3, 3), activation='relu'))
        model.add(MaxPool2D((2, 2)))
        model.add(Dropout(0.25))
        model.add(Flatten())
        model.add(Dense(1024, activation='relu'))
        model.add(Dropout(0.3))
        model.add(Dense(9, activation='softmax'))

        loss = tf.keras.losses.MeanSquaredError()
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)
        model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])

        model.fit(
            train_images,
            train_labels,
            batch_size=256,
            epochs=20,
            verbose=2,
            validation_data=(validation_images, validation_labels)
        )